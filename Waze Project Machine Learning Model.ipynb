{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Waze Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfCZ5KuI_2lT"
   },
   "source": [
    "Your team is close to completing their user churn project. Previously, you completed a project proposal, and used Python to explore and analyze Waze’s user data, create data visualizations, and conduct a hypothesis test. Most recently, you built a binomial logistic regression model based on multiple variables.\n",
    "\n",
    "Leadership appreciates all your hard work. Now, they want your team to build a machine learning model to predict user churn. To get the best results, your team decides to build and test two tree-based models: random forest and XGBoost.\n",
    "\n",
    "Your work will help leadership make informed business decisions to prevent user churn, improve user retention, and grow Waze’s business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# **Course 6 End-of-Course Project: Build a machine learning model**\n",
    "\n",
    "In this activity, you will practice using tree-based modeling techniques to predict on a binary target class.\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this model is to find factors that drive user churn.\n",
    "\n",
    "**The goal** of this model is to predict whether or not a Waze user is retained or churned.\n",
    "<br/>\n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Ethical considerations\n",
    "* Consider the ethical implications of the request\n",
    "\n",
    "* Should the objective of the model be adjusted?\n",
    "\n",
    "**Part 2:** Feature engineering\n",
    "\n",
    "* Perform feature selection, extraction, and transformation to prepare the data for modeling\n",
    "\n",
    "**Part 3:** Modeling\n",
    "\n",
    "* Build the models, evaluate them, and advise on next steps\n",
    "\n",
    "Follow the instructions and answer the questions below to complete the activity. Then, you will complete an Executive Summary using the questions listed on the PACE Strategy Document.\n",
    "\n",
    "Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsrI9g32nrAs"
   },
   "source": [
    "# **Build a machine learning model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzDjfCSLf6Jq"
   },
   "source": [
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "# **PACE stages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8kJRDEKn4A-"
   },
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5g1A74r0ow_"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## **PACE: Plan**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Plan stage.\n",
    "\n",
    "In this stage, consider the following questions:\n",
    "\n",
    "1.   What are you being asked to do?\n",
    "\n",
    "\n",
    "2.   What are the ethical implications of the model? What are the consequences of your model making errors?\n",
    "  *   What is the likely effect of the model when it predicts a false negative (i.e., when the model says a Waze user won't churn, but they actually will)?\n",
    "  *   What is the likely effect of the model when it predicts a false positive (i.e., when the model says a Waze user will churn, but they actually won't)?\n",
    "\n",
    "3.  Do the benefits of such a model outweigh the potential problems?\n",
    "4.  Would you proceed with the request to build this model? Why or why not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y755T4Q18iwC"
   },
   "source": [
    "1.   \n",
    "> _Predict if a customer will churn or be retained._\n",
    "\n",
    "2.   \n",
    "> _Waze will fail to take proactive measures to retain users who are likely to stop using the app. For example, Waze might proactively push an app notification to users, or send a survey to better understand user dissatisfaction. Waze may take proactive measures to retain users who are NOT likely to churn. This may lead to an annoying or negative experience for loyal users of the app._\n",
    "\n",
    "3.   \n",
    "  > _The proactive measueres taken by Waze might have unintended effects on users, and these effects might encourage user churn. Follow-up analysis on the effectiveness of the measures is recommended. If the measures are reasonable and effective, then the benefits will most likely outweigh the problems._\n",
    "\n",
    "4.   \n",
    ">_Yes. There aren't any significant risks for building such a model._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vm3QEfGELS"
   },
   "source": [
    "### **Task 1. Imports and data loading**\n",
    "\n",
    "Import packages and libraries needed to build and evaluate random forest and XGBoost classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "fKhnX2Puf4Bt"
   },
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import packages for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This lets us see all of the columns, preventing Juptyer from redacting them.\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Import packages for data modeling\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# This is the function that helps plot feature importance\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# This module lets us save our models once we fit them.\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeXTZ2tdbALL"
   },
   "source": [
    "Now read in the dataset as `df0` and inspect the first five rows.\n",
    "\n",
    "**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "5weTXGKqa_iG"
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df0 = pd.read_csv('waze_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "1HyORSaQo_LU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     label  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
       "0   0  retained       283     226      296.748273                     2276   \n",
       "1   1  retained       133     107      326.896596                     1225   \n",
       "2   2  retained       114      95      135.522926                     2651   \n",
       "3   3  retained        49      40       67.589221                       15   \n",
       "4   4  retained        84      68      168.247020                     1562   \n",
       "\n",
       "   total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
       "0                     208                       0       2628.845068   \n",
       "1                      19                      64      13715.920550   \n",
       "2                       0                       0       3059.148818   \n",
       "3                     322                       7        913.591123   \n",
       "4                     166                       5       3950.202008   \n",
       "\n",
       "   duration_minutes_drives  activity_days  driving_days   device  \n",
       "0              1985.775061             28            19  Android  \n",
       "1              3160.472914             13            11   iPhone  \n",
       "2              1610.735904             14             8  Android  \n",
       "3               587.196542              7             3   iPhone  \n",
       "4              1219.555924             27            18  Android  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first five rows\n",
    "df0.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgPRBjizg1oo"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Analyze**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VZowX9rhU1o"
   },
   "source": [
    "### **Task 2. Feature engineering**\n",
    "\n",
    "You have already prepared much of this data and performed exploratory data analysis (EDA) in previous courses. You know that some features had stronger correlations with churn than others, and you also created some features that may be useful.\n",
    "\n",
    "In this part of the project, you'll engineer these features and some new features to use for modeling.\n",
    "\n",
    "To begin, create a copy of `df0` to preserve the original dataframe. Call the copy `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "mBOSW8IDbO_d"
   },
   "outputs": [],
   "source": [
    "# Copy the df0 dataframe\n",
    "df = df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "teUeCF-yf_6o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       14999 non-null  int64  \n",
      " 1   label                    14299 non-null  object \n",
      " 2   sessions                 14999 non-null  int64  \n",
      " 3   drives                   14999 non-null  int64  \n",
      " 4   total_sessions           14999 non-null  float64\n",
      " 5   n_days_after_onboarding  14999 non-null  int64  \n",
      " 6   total_navigations_fav1   14999 non-null  int64  \n",
      " 7   total_navigations_fav2   14999 non-null  int64  \n",
      " 8   driven_km_drives         14999 non-null  float64\n",
      " 9   duration_minutes_drives  14999 non-null  float64\n",
      " 10  activity_days            14999 non-null  int64  \n",
      " 11  driving_days             14999 non-null  int64  \n",
      " 12  device                   14999 non-null  object \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "vAB6cv6xfvZn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.499900e+04\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      3.022063e+00\n",
       "25%      1.672804e+02\n",
       "50%      3.231459e+02\n",
       "75%      7.579257e+02\n",
       "max               inf\n",
       "Name: km_per_driving_day, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create `km_per_driving_day` feature\n",
    "df['km_per_driving_day'] = df['driven_km_drives']/df['driving_days']\n",
    "# 2. Get descriptive stats\n",
    "df['km_per_driving_day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "vv3owriWuuDQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14999.000000\n",
       "mean       578.963113\n",
       "std       1030.094384\n",
       "min          0.000000\n",
       "25%        136.238895\n",
       "50%        272.889272\n",
       "75%        558.686918\n",
       "max      15420.234110\n",
       "Name: km_per_driving_day, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert infinite values to zero\n",
    "df.loc[df['km_per_driving_day'] == np.inf] = 0\n",
    "# 2. Confirm that it worked\n",
    "df['km_per_driving_day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "4mRefXCF-K_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14999.000000\n",
       "mean       177.611943\n",
       "std        140.649351\n",
       "min          0.000000\n",
       "25%         75.964433\n",
       "50%        148.433445\n",
       "75%        246.098007\n",
       "max       1216.154633\n",
       "Name: total_sessions, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create `percent_sessions_in_last_month` feature\n",
    "df['percent_sessions_in_last_month'] = df['sessions'] / df['total_sessions']\n",
    "# 1. Get descriptive stats\n",
    "df['total_sessions'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "      <th>percent_sessions_in_last_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "      <td>138.360267</td>\n",
       "      <td>0.953670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1246.901868</td>\n",
       "      <td>0.406856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "      <td>382.393602</td>\n",
       "      <td>0.841186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>304.530374</td>\n",
       "      <td>0.724968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "      <td>219.455667</td>\n",
       "      <td>0.499266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     label  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
       "0   0  retained       283     226      296.748273                     2276   \n",
       "1   1  retained       133     107      326.896596                     1225   \n",
       "2   2  retained       114      95      135.522926                     2651   \n",
       "3   3  retained        49      40       67.589221                       15   \n",
       "4   4  retained        84      68      168.247020                     1562   \n",
       "\n",
       "   total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
       "0                     208                       0       2628.845068   \n",
       "1                      19                      64      13715.920550   \n",
       "2                       0                       0       3059.148818   \n",
       "3                     322                       7        913.591123   \n",
       "4                     166                       5       3950.202008   \n",
       "\n",
       "   duration_minutes_drives  activity_days  driving_days   device  \\\n",
       "0              1985.775061             28            19  Android   \n",
       "1              3160.472914             13            11   iPhone   \n",
       "2              1610.735904             14             8  Android   \n",
       "3               587.196542              7             3   iPhone   \n",
       "4              1219.555924             27            18  Android   \n",
       "\n",
       "   km_per_driving_day  percent_sessions_in_last_month  \n",
       "0          138.360267                        0.953670  \n",
       "1         1246.901868                        0.406856  \n",
       "2          382.393602                        0.841186  \n",
       "3          304.530374                        0.724968  \n",
       "4          219.455667                        0.499266  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "dQdMgikKU-5T"
   },
   "outputs": [],
   "source": [
    "# Create `professional_driver` feature\n",
    "\n",
    "df['professional_driver'] = np.where((df['drives'] >= 60) & (df['driving_days'] >= 15), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "bWXPMPHSVJQd"
   },
   "outputs": [],
   "source": [
    "# Create `total_sessions_per_day` feature\n",
    "df['total_sessions_per_day'] = df['total_sessions'] / df['n_days_after_onboarding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "h1DFSMNSVKEg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13975.000000\n",
       "mean         0.341241\n",
       "std          1.311070\n",
       "min          0.000298\n",
       "25%          0.050987\n",
       "50%          0.101053\n",
       "75%          0.216694\n",
       "max         39.763874\n",
       "Name: total_sessions_per_day, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get descriptive stats\n",
    "df['total_sessions_per_day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "Zu142H3aVc3o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13975.000000\n",
       "mean       190.692289\n",
       "std        341.112479\n",
       "min         72.015376\n",
       "25%         90.718081\n",
       "50%        122.293570\n",
       "75%        193.130119\n",
       "max      23642.920871\n",
       "Name: km_per_hour, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `km_per_hour` feature\n",
    "df['km_per_hour'] = df['driven_km_drives'] / (df['duration_minutes_drives'] / 60)\n",
    "df['km_per_hour'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d6N9jf8ViW-"
   },
   "source": [
    "#### **`km_per_drive`**\n",
    "\n",
    "Create a column representing the mean number of kilometers per drive made in the last month for each user. Then, print descriptive statistics for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "v5R5-MteVlMB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.397500e+04\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      1.008775e+00\n",
       "25%      3.313197e+01\n",
       "50%      7.461603e+01\n",
       "75%      1.850480e+02\n",
       "max               inf\n",
       "Name: km_per_drive, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `km_per_drive` feature\n",
    "df['km_per_drive'] = df['driven_km_drives'] / df['drives']\n",
    "df['km_per_drive'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txY8qR1LVlq1"
   },
   "source": [
    "This feature has infinite values too. Convert the infinite values to zero, then confirm that it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "PZrHMuPuVmIt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13975.000000\n",
       "mean       233.476375\n",
       "std        627.495672\n",
       "min          0.000000\n",
       "25%         32.221907\n",
       "50%         72.606220\n",
       "75%        179.254178\n",
       "max      15777.426560\n",
       "Name: km_per_drive, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert infinite values to zero\n",
    "df.loc[df['km_per_drive']==np.inf, 'km_per_drive'] = 0\n",
    "\n",
    "# 2. Confirm that it worked\n",
    "df['km_per_drive'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Sxs6agVunA"
   },
   "source": [
    "#### **`percent_of_sessions_to_favorite`**\n",
    "\n",
    "Finally, create a new column that represents the percentage of total sessions that were used to navigate to one of the users' favorite places. Then, print descriptive statistics for the new column.\n",
    "\n",
    "This is a proxy representation for the percent of overall drives that are to a favorite place. Since total drives since onboarding are not contained in this dataset, total sessions must serve as a reasonable approximation.\n",
    "\n",
    "People whose drives to non-favorite places make up a higher percentage of their total drives might be less likely to churn, since they're making more drives to less familiar places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "vh22o46AVxd_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13975.000000\n",
       "mean         1.688913\n",
       "std          9.153795\n",
       "min          0.000000\n",
       "25%          0.207423\n",
       "50%          0.649818\n",
       "75%          1.654002\n",
       "max        777.563629\n",
       "Name: percent_of_drives_to_favorite, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `percent_of_sessions_to_favorite` feature\n",
    "df['percent_of_drives_to_favorite'] = (\n",
    "    df['total_navigations_fav1'] + df['total_navigations_fav2']) / df['total_sessions']\n",
    "\n",
    "# Get descriptive stats\n",
    "df['percent_of_drives_to_favorite'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZO0mvHRWGmF"
   },
   "source": [
    "### **Task 3. Drop missing values**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "2TdA6SnGWJY-"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxBYyXDSWPkw"
   },
   "source": [
    "### **Task 4. Variable encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "fntUcR4-aUfH"
   },
   "outputs": [],
   "source": [
    "# Create new `device2` variable\n",
    "df['device2'] = np.where(df['device'] == 'iPhone', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "0jiVjplLb8W-"
   },
   "outputs": [],
   "source": [
    "# Create binary `label2` column\n",
    "df['label2'] = np.where(df['label'] == 'churned', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD_zG59eaV2c"
   },
   "source": [
    "### **Task 5. Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "kf3uGtUQaWSL"
   },
   "outputs": [],
   "source": [
    "# Drop `ID` column\n",
    "df = df.drop(['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajj50RCCaXrF"
   },
   "source": [
    "### **Task 6. Evaluation metric**\n",
    "\n",
    "Before modeling, you must decide on an evaluation metric. This will depend on the class balance of the target variable and the use case of the model.\n",
    "\n",
    "First, examine the class balance of your target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['retained', 'churned'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "3JkjEYByaYbr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "retained    0.839066\n",
       "churned     0.160934\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class balance of 'label' col\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9vnV1wtaZWJ"
   },
   "source": [
    "Approximately 18% of the users in this dataset churned. This is an unbalanced dataset, but not extremely so. It can be modeled without any class rebalancing.\n",
    "\n",
    "Now, consider which evaluation metric is best. Remember, accuracy might not be the best gauge of performance because a model can have high accuracy on an imbalanced dataset and still fail to predict the minority class.\n",
    "\n",
    "It was already determined that the risks involved in making a false positive prediction are minimal. No one stands to get hurt, lose money, or suffer any other significant consequence if they are predicted to churn. Therefore, select the model based on the recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n1eikFh8akS"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Construct**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Construct stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jzGjOS8iiv"
   },
   "source": [
    "### **Task 7. Modeling workflow and model selection process**\n",
    "\n",
    "The final modeling dataset contains 14,299 samples. This is towards the lower end of what might be considered sufficient to conduct a robust model selection process, but still doable.\n",
    "\n",
    "1. Split the data into train/validation/test sets (60/20/20)\n",
    "\n",
    "Note that, when deciding the split ratio and whether or not to use a validation set to select a champion model, consider both how many samples will be in each data partition, and how many examples of the minority class each would therefore contain. In this case, a 60/20/20 split would result in \\~2,860 samples in the validation set and the same number in the test set, of which \\~18%&mdash;or 515 samples&mdash;would represent users who churn.\n",
    "2. Fit models and tune hyperparameters on the training set\n",
    "3. Perform final model selection on the validation set\n",
    "4. Assess the champion model's performance on the test set\n",
    "\n",
    "![](https://raw.githubusercontent.com/adacert/tiktok/main/optimal_model_flow_numbered.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx41bVxX89Fe"
   },
   "source": [
    "### **Task 8. Split the data**\n",
    "\n",
    "\n",
    "1. Define a variable `X` that isolates the features. Remember not to use `device`.\n",
    "\n",
    "2. Define a variable `y` that isolates the target variable (`label2`).\n",
    "\n",
    "3. Split the data 80/20 into an interim training set and a test set. Don't forget to stratify the splits, and set the random state to 42.\n",
    "\n",
    "4. Split the interim training set 75/25 into a training set and a validation set, yielding a final ratio of 60/20/20 for training/validation/test sets. Again, don't forget to stratify the splits and set the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "qLbapbSWDUL-"
   },
   "outputs": [],
   "source": [
    "# 1. Isolate X variables\n",
    "X = df.drop(columns=['label', 'label2', 'device'])\n",
    "\n",
    "# 2. Isolate y variable\n",
    "y = df['label2']\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, stratify=y,\n",
    "                                              test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Split into train and validate sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, stratify=y_tr,\n",
    "                                                  test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moLls6Lech47"
   },
   "source": [
    "Verify the number of samples in the partitioned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "qWIog8v_ckIg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7989\n",
      "2663\n",
      "2664\n"
     ]
    }
   ],
   "source": [
    "for x in [X_train, X_val, X_test]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x-4vGANcki4"
   },
   "source": [
    "This aligns with expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vSaa0-xcu4Q"
   },
   "source": [
    "### **Task 9. Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "Vj5rJWOv5O3d"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [None],\n",
    "             'max_features': [1.0],\n",
    "             'max_samples': [1.0],\n",
    "             'min_samples_leaf': [2],\n",
    "             'min_samples_split': [2],\n",
    "             'n_estimators': [300],\n",
    "             }\n",
    "\n",
    "# 3. Define a list of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf_cv = GridSearchCV(rf, cv_params, scoring=scoring, cv=4, refit='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "OXuBiTGi5ZHn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 61.4 ms, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0],\n",
       "                         &#x27;max_samples&#x27;: [1.0], &#x27;min_samples_leaf&#x27;: [2],\n",
       "                         &#x27;min_samples_split&#x27;: [2], &#x27;n_estimators&#x27;: [300]},\n",
       "             refit=&#x27;recall&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0],\n",
       "                         &#x27;max_samples&#x27;: [1.0], &#x27;min_samples_leaf&#x27;: [2],\n",
       "                         &#x27;min_samples_split&#x27;: [2], &#x27;n_estimators&#x27;: [300]},\n",
       "             refit=&#x27;recall&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [None], 'max_features': [1.0],\n",
       "                         'max_samples': [1.0], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [2], 'n_estimators': [300]},\n",
       "             refit='recall', scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "YtAgrH0zy4CE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08164509200673362"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "kazNtYG4fQOI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best hyperparameter combo\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "u-UodWEOedxz"
   },
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, or accuracy\n",
    "\n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'precision': 'mean_test_precision',\n",
    "                   'recall': 'mean_test_recall',\n",
    "                   'f1': 'mean_test_f1',\n",
    "                   'accuracy': 'mean_test_accuracy',\n",
    "                   }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                          'precision': [precision],\n",
    "                          'recall': [recall],\n",
    "                          'F1': [f1],\n",
    "                          'accuracy': [accuracy],\n",
    "                          },\n",
    "                         )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "qAYb2QigiT_h"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF cv</td>\n",
       "      <td>0.434776</td>\n",
       "      <td>0.081645</td>\n",
       "      <td>0.137115</td>\n",
       "      <td>0.835273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  precision    recall        F1  accuracy\n",
       "0  RF cv   0.434776  0.081645  0.137115  0.835273"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "results = make_results('RF cv', rf_cv, 'recall')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB-yhW9uu7dO"
   },
   "source": [
    "Asside from the accuracy, the scores aren't that good. However, recall that when you built the logistic regression model in the last course the recall was \\~0.09, which means that this model has 33% better recall and about the same accuracy, and it was trained on less data.\n",
    "\n",
    "If you want, feel free to try retuning your hyperparameters to try to get a better score. You might be able to marginally improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOlktJ6l4Tgt"
   },
   "source": [
    "#### **XGBoost**\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "0ciO48nhiTqO"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [6, 12],\n",
    "             'min_child_weight': [3, 5],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'n_estimators': [300]\n",
    "             }\n",
    "\n",
    "# 3. Define a list of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYCWs_HX6804"
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "\n",
    "%%time\n",
    "\n",
    "xgb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFLTmIDm6805"
   },
   "outputs": [],
   "source": [
    "# Examine best score\n",
    "xgb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdPUCuND6805"
   },
   "outputs": [],
   "source": [
    "# Examine best parameters\n",
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QL19dH2h7KdD"
   },
   "outputs": [],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "xgb_cv_results = make_results('XGB cv', xgb_cv, 'recall')\n",
    "results = pd.concat([results, xgb_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5IRnMO27KdD"
   },
   "source": [
    "This model fit the data even better than the random forest model. The recall score is nearly double the recall score from the logistic regression model from the previous course, and it's almost 50% better than the random forest model's recall score, while maintaining a similar accuracy and precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfX0SjJffkh1"
   },
   "source": [
    "### **Task 10. Model selection**\n",
    "\n",
    "Now, use the best random forest model and the best XGBoost model to predict on the validation data. Whichever performs better will be selected as the champion model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chgR3Tx8fn1s"
   },
   "source": [
    "#### **Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUswawM2fyAf"
   },
   "outputs": [],
   "source": [
    "# Use random forest model to predict on validation data\n",
    "rf_val_preds = rf_cv.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJ9mCl0Uf4P4"
   },
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "        model_name (string): Your choice: how the model will be named in the output table\n",
    "        preds: numpy array of test predictions\n",
    "        y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "        table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                          'precision': [precision],\n",
    "                          'recall': [recall],\n",
    "                          'F1': [f1],\n",
    "                          'accuracy': [accuracy]\n",
    "                          })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22ANR4ZHf5NK"
   },
   "outputs": [],
   "source": [
    "# Get validation scores for RF model\n",
    "rf_val_scores = get_test_scores('RF val', rf_val_preds, y_val)\n",
    "\n",
    "# Append to the results table\n",
    "results = pd.concat([results, rf_val_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDeuk16igBD0"
   },
   "source": [
    "Notice that the scores went down from the training scores across all metrics, but only by very little. This means that the model did not overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8h2s5RpgEER"
   },
   "source": [
    "#### **XGBoost**\n",
    "\n",
    "Now, do the same thing to get the performance scores of the XGBoost model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQoTuRkngHjp"
   },
   "outputs": [],
   "source": [
    "# Use XGBoost model to predict on validation data\n",
    "xgb_val_preds = xgb_cv.best_estimator_.predict(X_val)\n",
    "\n",
    "# Get validation scores for XGBoost model\n",
    "xgb_val_scores = get_test_scores('XGB val', xgb_val_preds, y_val)\n",
    "\n",
    "# Append to the results table\n",
    "results = pd.concat([results, xgb_val_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GspkQqUNgIm3"
   },
   "source": [
    "Just like with the random forest model, the XGBoost model's validation scores were lower, but only very slightly. It is still the clear champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HGsWfEOeWPm"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Execute**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Execute stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOm4n_1OgUND"
   },
   "source": [
    "### **Task 11. Use champion model to predict on test data**\n",
    "\n",
    "Now, use the champion model to predict on the test dataset. This is to give a final indication of how you should expect the model to perform on new future data, should you decide to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BkheTIsgU2b"
   },
   "outputs": [],
   "source": [
    "# Use XGBoost model to predict on test data\n",
    "xgb_test_preds = xgb_cv.best_estimator_.predict(X_test)\n",
    "\n",
    "# Get test scores for XGBoost model\n",
    "xgb_test_scores = get_test_scores('XGB test', xgb_test_preds, y_test)\n",
    "\n",
    "# Append to the results table\n",
    "results = pd.concat([results, xgb_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8L_LyIbgV1I"
   },
   "source": [
    "The recall was exactly the same as it was on the validation data, but the precision declined notably, which caused all of the other scores to drop slightly. Nonetheless, this is stil within the acceptable range for performance discrepancy between validation and test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5GNoz_QgWug"
   },
   "source": [
    "### **Task 12. Confusion matrix**\n",
    "\n",
    "Plot a confusion matrix of the champion model's predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WF3KErX8gXPc"
   },
   "outputs": [],
   "source": [
    "# Generate array of values for confusion matrix\n",
    "cm = confusion_matrix(y_test, xgb_test_preds, labels=xgb_cv.classes_)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=['retained', 'churned'])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xL4OujkgYC3"
   },
   "source": [
    "The model predicted three times as many false negatives than it did false positives, and it correctly identified only 16.6% of the users who actually churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P33INGPmgY1o"
   },
   "source": [
    "### **Task 13. Feature importance**\n",
    "\n",
    "Use the `plot_importance` function to inspect the most important features of your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4fc2i8XgZoE"
   },
   "outputs": [],
   "source": [
    "plot_importance(xgb_cv.best_estimator_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU3GIZNrga5z"
   },
   "source": [
    "The XGBoost model made more use of many of the features than did the logistic regression model from the previous course, which weighted a single feature (`activity_days`) very heavily in its final prediction.\n",
    "\n",
    "If anything, this underscores the importance of feature engineering. Notice that engineered features accounted for six of the top 10 features (and three of the top five). Feature engineering is often one of the best and easiest ways to boost model performance.\n",
    "\n",
    "Also, note that the important features in one model might not be the same as the important features in another model. That's why you shouldn't discount features as unimportant without thoroughly examining them and understanding their relationship with the dependent variable, if possible. These discrepancies between features selected by models are typically caused by complex feature interactions.\n",
    "\n",
    "Remember, sometimes your data simply will not be predictive of your chosen target. This is common. Machine learning is a powerful tool, but it is not magic. If your data does not contain predictive signal, even the most complex algorithm will not be able to deliver consistent and accurate predictions. Do not be afraid to draw this conclusion.\n",
    "\n",
    "Even if you cannot use the model to make strong predictions, was the work done in vain? What insights can you report back to stakeholders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ill21hQ4ej9-"
   },
   "source": [
    "### **Task 14. Conclusion**\n",
    "\n",
    "Now we share our findings with the Waze team. What are some things to consider?\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Would you recommend using this model for churn prediction? Why or why not?\n",
    "\n",
    "2. What tradeoff was made by splitting the data into training, validation, and test sets as opposed to just training and test sets?\n",
    "\n",
    "3. What is the benefit of using a logistic regression model over an ensemble of tree-based models (like random forest or XGBoost) for classification tasks?\n",
    "\n",
    "4. What is the benefit of using an ensemble of tree-based models like random forest or XGBoost over a logistic regression model for classification tasks?\n",
    "\n",
    "5. What could you do to improve this model?\n",
    "\n",
    "6. What additional features would you like to have to help improve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NrXTUydBady"
   },
   "source": [
    "1. Would you recommend using this model for churn prediction? Why or why not?\n",
    "\n",
    "> _It depends. What would the model be used for? If it's used to drive consequential business decisions, then no. The model is not a strong enough predictor, as made clear by its poor recall score. However, if the model is only being used to guide further exploratory efforts, then it can have value._\n",
    "\n",
    "2. What tradeoff was made by splitting the data into training, validation, and test sets as opposed to just training and test sets?\n",
    "\n",
    "> _Splitting the data three ways means that there is less data available to train the model than splitting just two ways. However, performing model selection on a separate validation set enables testing of the champion model by itself on the test set, which gives a better estimate of future performance than splitting the data two ways and selecting a champion model by performance on the test data._\n",
    "\n",
    "3. What is the benefit of using a logistic regression model over an ensemble of tree-based models (like random forest or XGBoost) for classification tasks?\n",
    "\n",
    "> _Logistic regression models are easier to interpret. Because they assign coefficients to predictor variables, they reveal not only which features factored most heavily into their final predictions, but also the directionality of the weight. In other words, they tell you if each feature is positively or negatively correlated with the target in the model's final prediction._\n",
    "\n",
    "4. What is the benefit of using an ensemble of tree-based models like random forest or XGBoost over a logistic regression model for classification tasks?\n",
    "\n",
    "> _Tree-based model ensembles are often better predictors. If the most important thing is the predictive power of the model, then tree-based modeling will usually win out against logistic regression (but not always!). They also require much less data cleaning and require fewer assumptions about the underlying distributions of their predictor variables, so they're easier to work with._\n",
    "\n",
    "5. What could you do to improve this model?\n",
    "\n",
    "> _New features could be engineered to try to generate better predictive signal, as they often do if you have domain knowledge. In the case of this model, the engineered features made up over half of the top 10 most-predictive features used by the model. It could also be helpful to reconstruct the model with different combinations of predictor variables to reduce noise from unpredictive features._\n",
    "\n",
    "6. What additional features would you like to have to help improve the model?\n",
    "\n",
    "> _It would be helpful to have drive-level information for each user (such as drive times, geographic locations, etc.). It would probably also be helpful to have more granular data to know how users interact with the app. For example, how often do they report or confirm road hazard alerts? Finally, it could be helpful to know the monthly count of unique starting and ending locations each driver inputs._\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1DHsmIEwaXUmfVT4tFzyOwyyfXAX0v6IF",
     "timestamp": 1675262571681
    },
    {
     "file_id": "1oNheYh5WbljxkvoK_BMkQTey2DWnFXMs",
     "timestamp": 1674856595373
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
